# Backend API Keys
# Get your API key from https://auto.dev
AUTO_DEV_API_KEY=your_auto_dev_api_key_here

# LLM Configuration (for local Llama or other OpenAI-compatible server)
# Default is Ollama running locally
LLM_API_BASE=http://127.0.0.1:11434/v1
LLM_MODEL_NAME=llama3
LLM_API_KEY=
LLM_TIMEOUT_SECONDS=30

# Frontend Configuration (for frontend/.env)
# URL where your FastAPI backend is running
BACKEND_URL=http://localhost:8000
